{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Google Search Grounding with the Gemini API\n",
        "\n",
        "This notebook introduces **search grounding** as a method for connecting language model outputs to **verifiable external sources**. Instead of relying solely on the model’s internal knowledge, grounding allows the model to retrieve and reference up-to-date information from Google Search, making it possible to inspect and verify the evidence used in an answer.\n",
        "\n",
        "Conceptually, search grounding is similar to Retrieval-Augmented Generation (RAG), but the retrieval step is handled automatically by the Gemini API. The model generates search queries, retrieves relevant documents from the web, and returns responses together with links to supporting sources. This is particularly useful in research settings where transparency, traceability, and source verification are required.\n",
        "\n",
        "### Model and access notes\n",
        "\n",
        "Gemini 2.0 Flash includes access to Google Search grounding under the free tier, making it suitable for experimentation and teaching. Earlier Gemini models require billing to be enabled for grounding features. Regardless of model choice, grounded outputs should be treated as **starting points for verification**, not as authoritative evidence.\n",
        "\n",
        "This notebook demonstrates how search grounding can support research workflows such as literature scanning, policy analysis, and claim verification, while maintaining an auditable link between generated text and underlying sources.\n"
      ],
      "metadata": {
        "id": "q-mcOl0JY8Xg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional: Use Google AI Studio\n",
        "\n",
        "If you wish to try out grounding with Google Search, follow this section to try it out using the AI Studio interface. Or skip ahead to the `API` section to try the feature here in your notebook.\n",
        "\n",
        "### Open AI Studio\n",
        "\n",
        "Start by going to [AI Studio](https://aistudio.google.com/prompts/new_chat). You should be in the \"New chat\" interface.\n",
        "\n",
        "Search Grounding is best with `gemini-2.0-flash`, but try out `gemini-1.5-flash` too.\n",
        "\n",
        "![New chat in AI Studio](https://storage.googleapis.com/generativeai-downloads/kaggle/ais-newchat.png)\n",
        "\n",
        "### Ask a question\n",
        "\n",
        "Now enter a prompt into the chat interface. Try asking something that is timely and might require recent information to answer, like a recent sport score. For this query, grounding will be **disabled** by default.\n",
        "\n",
        "\n",
        "![Sample question-answer pair without grounding](https://storage.googleapis.com/generativeai-downloads/kaggle/cricket-ungrounded.png)\n",
        "\n",
        "### Enable grounding\n",
        "\n",
        "On the right-hand sidebar, under the `Tools` section. Find and enable the `Grounding` option.\n",
        "\n",
        "![Enable grounding button](https://storage.googleapis.com/generativeai-downloads/kaggle/enable-grounding.png)\n",
        "\n",
        "Now re-run your question by hovering over the user prompt in the chat history, and pressing the Gemini ✨ icon to re-run your prompt.\n",
        "\n",
        "![Re-run prompt button](https://storage.googleapis.com/generativeai-downloads/kaggle/re-run-button.png)\n",
        "\n",
        "You should now see a response generated that references sources from Google Search.\n",
        "\n",
        "![Response with grounded sources from Google!](https://storage.googleapis.com/generativeai-downloads/kaggle/cricket-grounded.png)\n",
        "\n",
        "\n",
        "### Try your own queries\n",
        "\n",
        "Explore this interface and try some other queries. Share what works well in the [Discord](https://discord.com/channels/1101210829807956100/1303438361117069363)! You can start from [this blank template](https://aistudio.google.com/app/prompts/1FZtxKLFZIJ1p_0rICu8K2CNIF1tkAnf4) that has search grounding enabled.\n",
        "\n",
        "The remaining steps require an API key with billing enabled. They are not required to complete this course; if you have tried grounding in AI Studio you are done for this notebook."
      ],
      "metadata": {
        "id": "YlgDoqFFfGis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use the API\n",
        "\n",
        "Start by installing and importing the Gemini API Python SDK."
      ],
      "metadata": {
        "id": "Qcyq976Gbwpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Uninstall packages from Kaggle base image that are not needed.\n",
        "!pip uninstall -qy jupyterlab jupyterlab-lsp\n",
        "# Install the google-genai SDK for this codelab.\n",
        "!pip install -qU 'google-genai==1.7.0'"
      ],
      "metadata": {
        "id": "1ZLC4ORSbqme",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T09:58:12.342823Z",
          "iopub.execute_input": "2025-04-03T09:58:12.3433Z",
          "iopub.status.idle": "2025-04-03T09:58:30.65952Z",
          "shell.execute_reply.started": "2025-04-03T09:58:12.343251Z",
          "shell.execute_reply": "2025-04-03T09:58:30.658231Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "from IPython.display import Markdown, HTML, display\n",
        "\n",
        "\n",
        "genai.__version__"
      ],
      "metadata": {
        "id": "FNkHtOAmbt2B",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T09:58:30.661065Z",
          "iopub.execute_input": "2025-04-03T09:58:30.661416Z",
          "iopub.status.idle": "2025-04-03T09:58:31.952191Z",
          "shell.execute_reply.started": "2025-04-03T09:58:30.661383Z",
          "shell.execute_reply": "2025-04-03T09:58:31.951108Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3dde87d4-b872-4d8a-c1bc-ee1203225fbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.61.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a [Kaggle secret](https://www.kaggle.com/discussions/product-feedback/114053) named `GOOGLE_API_KEY`.\n",
        "\n",
        "If you don't already have an API key, you can grab one from [AI Studio](https://aistudio.google.com/app/apikey). You can find [detailed instructions in the docs](https://ai.google.dev/gemini-api/docs/api-key).\n",
        "\n",
        "To make the key available through Kaggle secrets, choose `Secrets` from the `Add-ons` menu and follow the instructions to add your key or enable it for this notebook."
      ],
      "metadata": {
        "id": "_NO9cdffb4KR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from google import genai\n",
        "\n",
        "API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "client = genai.Client(api_key=API_KEY)\n"
      ],
      "metadata": {
        "id": "8NAmACYHb5DK",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T09:58:31.953579Z",
          "iopub.execute_input": "2025-04-03T09:58:31.954128Z",
          "iopub.status.idle": "2025-04-03T09:58:32.184023Z",
          "shell.execute_reply.started": "2025-04-03T09:58:31.954086Z",
          "shell.execute_reply": "2025-04-03T09:58:32.182796Z"
        }
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Automated retry"
      ],
      "metadata": {
        "id": "FsPs7dv5fGit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a retry policy. The model might make multiple consecutive calls automatically\n",
        "# for a complex query, this ensures the client retries if it hits quota limits.\n",
        "from google.api_core import retry\n",
        "\n",
        "is_retriable = lambda e: (isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
        "\n",
        "if not hasattr(genai.models.Models.generate_content, '__wrapped__'):\n",
        "  genai.models.Models.generate_content = retry.Retry(\n",
        "      predicate=is_retriable)(genai.models.Models.generate_content)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T09:58:32.185293Z",
          "iopub.execute_input": "2025-04-03T09:58:32.185642Z",
          "iopub.status.idle": "2025-04-03T09:58:32.361998Z",
          "shell.execute_reply.started": "2025-04-03T09:58:32.18559Z",
          "shell.execute_reply": "2025-04-03T09:58:32.361142Z"
        },
        "id": "-hRKEEi7fGit"
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use search grounding\n",
        "\n",
        "### Model support\n",
        "\n",
        "Search grounding is available in a limited set of models. Find a model that supports it on [the models page](https://ai.google.dev/gemini-api/docs/models/gemini).\n",
        "\n",
        "In this guide, you'll use `gemini-2.0-flash`."
      ],
      "metadata": {
        "id": "Rvre6fOrcHi2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make a request\n",
        "\n",
        "To enable search grounding, you specify it as a tool: `google_search`. Like other tools, this is supplied as a parameter in `GenerateContentConfig`, and can be passed to `generate_content` calls as well as `chats.create` (for all chat turns) or `chat.send_message` (for specific turns).\n"
      ],
      "metadata": {
        "id": "HW5RVNUierrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask for information without search grounding.\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-3-flash-preview\",\n",
        "    contents=\"When was the most recent update to Australia's national housing affordability policy?\"\n",
        ")\n",
        "\n",
        "Markdown(response.text)"
      ],
      "metadata": {
        "id": "JZmdaOlVfCgd",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T09:58:32.363299Z",
          "iopub.execute_input": "2025-04-03T09:58:32.363783Z",
          "iopub.status.idle": "2025-04-03T09:58:33.200317Z",
          "shell.execute_reply.started": "2025-04-03T09:58:32.363749Z",
          "shell.execute_reply": "2025-04-03T09:58:33.199271Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 756
        },
        "outputId": "f7fae2be-8b7b-4983-ef3a-04692e8bc110"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The most recent and significant update to Australia’s national housing affordability policy occurred on **July 1, 2024**, with the commencement of the new **National Agreement on Social Housing and Homelessness (NASHH)**.\n\nThis agreement replaced the previous National Housing and Homelessness Agreement (NHHA) and represents a major structural shift in how the Federal Government funds states and territories for housing.\n\nHere is a breakdown of the most recent updates and policy milestones:\n\n### 1. The National Agreement on Social Housing and Homelessness (July 1, 2024)\nThis is a **$9.3 billion, five-year agreement** between the Commonwealth and the States and Territories.\n*   **Purpose:** To provide long-term funding for social housing and homelessness services.\n*   **Key Update:** It includes a significant increase in funding (roughly $400 million extra per year) compared to the previous agreement, specifically targeted at homelessness services and social housing maintenance.\n\n### 2. The \"Homes for Australia\" Plan (May 2024 Budget)\nIn the May 2024 Federal Budget, the Albanese Government announced a **$11.3 billion** housing package. Key updates included:\n*   **Rent Assistance:** A further 10% increase in the maximum rates of Commonwealth Rent Assistance (following a 15% increase in 2023).\n*   **Infrastructure Fund:** The creation of a **$1 billion** fund for states and territories to fast-track the building of infrastructure (sewerage, water, roads) needed to unlock new housing developments.\n*   **Social Housing:** An additional $1 billion specifically for crisis accommodation and housing for women and children fleeing domestic violence.\n\n### 3. The Housing Australia Future Fund (HAFF) Operations (2024)\nWhile the legislation for the HAFF passed in **September 2023**, the first round of funding applications closed in **early 2024**.\n*   This is a $10 billion investment fund where the returns are used to build 30,000 new social and affordable rental homes over five years.\n*   The first round of successful projects and funding allocations are currently being rolled out as of mid-2024.\n\n### 4. Help to Buy Scheme (Ongoing Legislation)\nAs of late 2024, the government is still attempting to pass the **\"Help to Buy\" Bill**.\n*   This is a \"shared equity\" scheme where the government would provide up to 40% of the purchase price for new homes.\n*   This remains a point of political contention in the Senate and has not yet been fully implemented nationally.\n\n### 5. National Housing and Homelessness Plan (Upcoming - Late 2024)\nThe government is currently finalizing a **10-year National Housing and Homelessness Plan**. \n*   This is intended to be the \"master document\" that coordinates policy across all levels of government, industry, and the community sector. \n*   The final version is expected to be released in **late 2024** following extensive public consultation that concluded in late 2023.\n\n### Summary\nIf you are looking for the \"most recent\" change, it is the **July 1, 2024** implementation of the **NASHH** agreement and the **Rent Assistance** increases that took effect following the May 2024 Budget."
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now try with grounding enabled.\n"
      ],
      "metadata": {
        "id": "A6tl-8fjfGit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# And now re-run the same query with search grounding enabled.\n",
        "config_with_search = types.GenerateContentConfig(\n",
        "    tools=[types.Tool(google_search=types.GoogleSearch())],\n",
        ")\n",
        "\n",
        "def query_with_grounding():\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-3-flash-preview\",\n",
        "        contents=\"When was the most recent update to Australia's national housing affordability policy?\",\n",
        "        config=config_with_search,\n",
        "    )\n",
        "    return response.candidates[0]\n",
        "\n",
        "\n",
        "rc = query_with_grounding()\n",
        "Markdown(rc.content.parts[0].text)"
      ],
      "metadata": {
        "id": "i7jqG3nww6kU",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T10:06:10.714532Z",
          "iopub.execute_input": "2025-04-03T10:06:10.714952Z",
          "iopub.status.idle": "2025-04-03T10:06:12.996772Z",
          "shell.execute_reply.started": "2025-04-03T10:06:10.714915Z",
          "shell.execute_reply": "2025-04-03T10:06:12.995712Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Response metadata\n",
        "\n",
        "When search grounding is used, the model returns extra metadata that includes links to search suggestions, supporting documents and information on how the supporting documents were used.\n",
        "\n",
        "Each \"grounding chunk\" represents information retrieved from Google Search that was used in the grounded generation request. Following the URI will take you to the source."
      ],
      "metadata": {
        "id": "SJc_0FFBgoiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while not rc.grounding_metadata.grounding_supports or not rc.grounding_metadata.grounding_chunks:\n",
        "    # If incomplete grounding data was returned, retry.\n",
        "    rc = query_with_grounding()\n",
        "\n",
        "chunks = rc.grounding_metadata.grounding_chunks\n",
        "for chunk in chunks:\n",
        "    print(f'{chunk.web.title}: {chunk.web.uri}')"
      ],
      "metadata": {
        "id": "2P7IYMcvxtcy",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T10:06:16.348495Z",
          "iopub.execute_input": "2025-04-03T10:06:16.348902Z",
          "iopub.status.idle": "2025-04-03T10:06:16.355194Z",
          "shell.execute_reply.started": "2025-04-03T10:06:16.348868Z",
          "shell.execute_reply": "2025-04-03T10:06:16.354002Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "As part of the response, there is a standalone styled HTML content block that you use to link back to relevant search suggestions related to the generation."
      ],
      "metadata": {
        "id": "ziYb2Fkjzwwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "HTML(rc.grounding_metadata.search_entry_point.rendered_content)"
      ],
      "metadata": {
        "id": "DQAgIGJmfxqC",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T09:51:45.325784Z",
          "iopub.status.idle": "2025-04-03T09:51:45.326372Z",
          "shell.execute_reply.started": "2025-04-03T09:51:45.326076Z",
          "shell.execute_reply": "2025-04-03T09:51:45.326106Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `grounding_supports` in the metadata provide a way for you to correlate the grounding chunks used to the generated output text."
      ],
      "metadata": {
        "id": "pJpqJopp0H0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "\n",
        "supports = rc.grounding_metadata.grounding_supports\n",
        "for support in supports:\n",
        "    pprint(support.to_json_dict())"
      ],
      "metadata": {
        "id": "sHg9Yq9U0r89",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T10:06:19.447653Z",
          "iopub.execute_input": "2025-04-03T10:06:19.448041Z",
          "iopub.status.idle": "2025-04-03T10:06:19.455269Z",
          "shell.execute_reply.started": "2025-04-03T10:06:19.448006Z",
          "shell.execute_reply": "2025-04-03T10:06:19.454225Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "These supports can be used to highlight text in the response, or build tables of footnotes."
      ],
      "metadata": {
        "id": "wkQAGyi87FGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "markdown_buffer = io.StringIO()\n",
        "\n",
        "# Print the text with footnote markers.\n",
        "markdown_buffer.write(\"Supported text:\\n\\n\")\n",
        "for support in supports:\n",
        "    markdown_buffer.write(\" * \")\n",
        "    markdown_buffer.write(\n",
        "        rc.content.parts[0].text[support.segment.start_index : support.segment.end_index]\n",
        "    )\n",
        "\n",
        "    for i in support.grounding_chunk_indices:\n",
        "        chunk = chunks[i].web\n",
        "        markdown_buffer.write(f\"<sup>[{i+1}]</sup>\")\n",
        "\n",
        "    markdown_buffer.write(\"\\n\\n\")\n",
        "\n",
        "\n",
        "# And print the footnotes.\n",
        "markdown_buffer.write(\"Citations:\\n\\n\")\n",
        "for i, chunk in enumerate(chunks, start=1):\n",
        "    markdown_buffer.write(f\"{i}. [{chunk.web.title}]({chunk.web.uri})\\n\")\n",
        "\n",
        "\n",
        "Markdown(markdown_buffer.getvalue())"
      ],
      "metadata": {
        "id": "9_dEINt43C62",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T10:06:21.640644Z",
          "iopub.execute_input": "2025-04-03T10:06:21.641418Z",
          "iopub.status.idle": "2025-04-03T10:06:21.650514Z",
          "shell.execute_reply.started": "2025-04-03T10:06:21.641377Z",
          "shell.execute_reply": "2025-04-03T10:06:21.64942Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Search with tools\n",
        "\n",
        "In this example, you'll use enable the Google Search grounding tool and the code generation tool across two steps. In the first step, the model will use Google Search to find the requested information and then in the follow-up question, it generates code to plot the results.\n",
        "\n",
        "This usage includes textual, visual and code parts, so first define a function to help visualise these."
      ],
      "metadata": {
        "id": "BUmUIvjlfGiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Image, Markdown\n",
        "\n",
        "def show_response(response):\n",
        "    for p in response.candidates[0].content.parts:\n",
        "        if p.text:\n",
        "            display(Markdown(p.text))\n",
        "        elif p.inline_data:\n",
        "            display(Image(p.inline_data.data))\n",
        "        else:\n",
        "            print(p.to_json_dict())\n",
        "\n",
        "        display(Markdown('----'))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T10:06:32.135955Z",
          "iopub.execute_input": "2025-04-03T10:06:32.137085Z",
          "iopub.status.idle": "2025-04-03T10:06:32.144267Z",
          "shell.execute_reply.started": "2025-04-03T10:06:32.137025Z",
          "shell.execute_reply": "2025-04-03T10:06:32.143171Z"
        },
        "id": "0e2kJEPsfGiu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now start a chat asking for some information. Here you provide the Google Search tool so that the model can look up data from Google's Search index."
      ],
      "metadata": {
        "id": "5VAJrOETfGiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_with_search = types.GenerateContentConfig(\n",
        "    tools=[types.Tool(google_search=types.GoogleSearch())],\n",
        "    temperature=0.0,\n",
        ")\n",
        "\n",
        "chat = client.chats.create(model='gemini-2.0-flash')\n",
        "\n",
        "response = chat.send_message(\n",
        "    message=\"What were the medal tallies, by top-10 countries, for the 2024 olympics?\",\n",
        "    config=config_with_search,\n",
        ")\n",
        "\n",
        "show_response(response)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T10:06:57.31514Z",
          "iopub.execute_input": "2025-04-03T10:06:57.31568Z",
          "iopub.status.idle": "2025-04-03T10:06:59.731547Z",
          "shell.execute_reply.started": "2025-04-03T10:06:57.315631Z",
          "shell.execute_reply": "2025-04-03T10:06:59.730267Z"
        },
        "id": "xC8zrf5dfGiu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continuing the chat, now ask the model to convert the data into a chart. The `code_execution` tool is able to generate code to draw charts, execute that code and return the image. You can see the executed code in the `executable_code` part of the response.\n",
        "\n",
        "Combining results from Google Search with tools like live plotting can enable very powerful use cases that require very little code to run."
      ],
      "metadata": {
        "id": "YtqjGEOnfGiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_with_code = types.GenerateContentConfig(\n",
        "    tools=[types.Tool(code_execution=types.ToolCodeExecution())],\n",
        "    temperature=0.0,\n",
        ")\n",
        "\n",
        "response = chat.send_message(\n",
        "    message=\"Now plot this as a seaborn chart. Break out the medals too.\",\n",
        "    config=config_with_code,\n",
        ")\n",
        "\n",
        "show_response(response)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-04-03T10:06:59.73333Z",
          "iopub.execute_input": "2025-04-03T10:06:59.733656Z",
          "iopub.status.idle": "2025-04-03T10:07:04.594013Z",
          "shell.execute_reply.started": "2025-04-03T10:06:59.733624Z",
          "shell.execute_reply": "2025-04-03T10:07:04.592928Z"
        },
        "id": "wOvUj4s7fGiu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Further reading\n",
        "\n",
        "When using search grounding, there are some specific requirements that you must follow, including when and how to show search suggestions, and how to use the grounding links.  Be sure to read and follow the details in the [search grounding capability guide](https://ai.google.dev/gemini-api/docs/grounding) and the [search suggestions guide](https://ai.google.dev/gemini-api/docs/grounding/search-suggestions).\n",
        "\n",
        "Also check out some more compelling examples of using search grounding with the Live API in the [cookbook](https://github.com/google-gemini/cookbook/), like [this example that uses Google Maps to plot Search results on a map](https://github.com/google-gemini/cookbook/blob/main/examples/LiveAPI_plotting_and_mapping.ipynb) in an audio conversation, or [this example](https://github.com/google-gemini/cookbook/blob/main/examples/Search_grounding_for_research_report.ipynb) that builds a comprehensive research report.\n",
        "\n",
        "*- [Mark McD](https://linktr.ee/markmcd)*"
      ],
      "metadata": {
        "id": "Cp7gvdM-zOf0"
      }
    }
  ]
}